# modules/spec_orchestrator.py
"""
Spec Orchestrator v2.0 (Production-Grade with Enhanced AI)

NEW FEATURES:
‚úÖ RAG Engine integration for intelligent test suggestions
‚úÖ Learning Memory integration for historical insights
‚úÖ Intelligent Test Selector for optimized test execution
‚úÖ Enhanced error recovery with detailed diagnostics
‚úÖ Streaming support for real-time progress updates
‚úÖ Test recommendation based on code changes
‚úÖ Flaky test detection and filtering

PRESERVED FEATURES:
‚úÖ State recovery (resume from checkpoint)
‚úÖ UUID-based run IDs for traceability
‚úÖ Telemetry export (Prometheus + JSONL)
‚úÖ Dry-run mode for safe testing
‚úÖ Event hooks for extensibility
‚úÖ Graceful security engine fallback
‚úÖ JSON Schema plan validation
"""

from __future__ import annotations
import json
import logging
import time
import uuid
from typing import Dict, Any, Optional, List, Protocol, Callable, Iterator
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass, field, asdict
from enum import Enum

logger = logging.getLogger(__name__)

# ==================== Core modules ====================
from modules.conversational_agent import ConversationalAgent
from modules.web_scraper import WebScraper
from modules.test_generator import TestGenerator
from modules.runner import Runner

# ==================== NEW: AI-Enhanced modules ====================
from modules.rag_engine import RAGEngine
from modules.learning_memory import LearningMemory
from modules.test_selector import IntelligentTestSelector

# Optional: Security engine (graceful fallback)
try:
    from modules.security_engine import SecurityEngine
    SECURITY_ENGINE_AVAILABLE = True
except Exception as e:
    SECURITY_ENGINE_AVAILABLE = False
    logger.warning("SecurityEngine not available: %s. Security checks disabled.", e)

# Optional: JSON Schema validation
try:
    from jsonschema import validate as jsonschema_validate, ValidationError as JSONSchemaValidationError
    JSON_SCHEMA_AVAILABLE = True
except Exception:
    JSON_SCHEMA_AVAILABLE = False
    logger.info("jsonschema not installed. Plan validation disabled.")

# Optional: Prometheus metrics
try:
    from prometheus_client import Counter, Histogram, Gauge, start_http_server, generate_latest
    PROMETHEUS_AVAILABLE = True
except Exception:
    PROMETHEUS_AVAILABLE = False
    logger.info("prometheus_client not installed. Metrics export disabled.")


# ==================== Configuration ====================

@dataclass
class OrchestratorConfig:
    """Centralized configuration for the orchestrator."""
    # Scraper settings
    scraper_max_pages: int = 20
    scraper_max_depth: int = 2
    scraper_timeout_ms: int = 40000
    scraper_post_load_wait_ms: int = 1500
    scraper_same_origin: bool = True
    scraper_capture_api: bool = True
    scraper_rate_limit_s: float = 1.5
    scraper_respect_robots: bool = False
    scraper_exclude: Optional[List[str]] = None
    
    # Generator settings
    html_cache_dir: str = "data/scraped_docs"
    
    # UI config defaults
    ui_browsers: str = "chromium"
    ui_headless: bool = True
    ui_test_timeout_ms: int = 45000
    ui_expect_timeout_ms: int = 8000
    ui_workers: int = 4
    ui_retries: int = 1
    ui_fully_parallel: bool = False
    ui_forbid_only: bool = True
    ui_enable_junit: bool = True
    
    # Orchestrator settings
    enable_api_discovery: bool = True
    enable_security_checks: bool = True
    api_discovery_limit: int = 50
    retry_max_attempts: int = 3
    retry_delay_s: float = 2.0
    enable_state_persistence: bool = True
    state_file: str = "data/orchestrator_state.json"
    
    # Dry-run mode
    dry_run: bool = False
    
    # Plan validation
    enable_plan_validation: bool = True
    plan_schema_file: Optional[str] = "schemas/test_plan.schema.json"
    
    # Telemetry
    enable_prometheus_metrics: bool = False
    prometheus_port: int = 9090
    enable_jsonl_export: bool = True
    metrics_export_dir: str = "data/metrics"
    
    # ‚ú® NEW: AI-Enhanced features
    enable_rag: bool = True
    enable_learning_memory: bool = True
    enable_intelligent_selection: bool = True
    enable_streaming: bool = False
    rag_top_k: int = 5
    learning_memory_days: int = 30
    
    @classmethod
    def from_env(cls) -> "OrchestratorConfig":
        """Load configuration from environment variables."""
        import os
        return cls(
            scraper_max_pages=int(os.getenv("SCRAPER_MAX_PAGES", "20")),
            scraper_max_depth=int(os.getenv("SCRAPER_MAX_DEPTH", "2")),
            scraper_timeout_ms=int(os.getenv("SCRAPER_TIMEOUT_MS", "40000")),
            scraper_post_load_wait_ms=int(os.getenv("SCRAPER_POST_LOAD_WAIT_MS", "1500")),
            scraper_same_origin=os.getenv("SCRAPER_SAME_ORIGIN", "true").lower() == "true",
            scraper_capture_api=os.getenv("SCRAPER_CAPTURE_API", "true").lower() == "true",
            scraper_rate_limit_s=float(os.getenv("SCRAPER_RATE_LIMIT_S", "1.5")),
            dry_run=os.getenv("DRY_RUN", "false").lower() == "true",
            enable_prometheus_metrics=os.getenv("ENABLE_PROMETHEUS", "false").lower() == "true",
            enable_rag=os.getenv("ENABLE_RAG", "true").lower() == "true",
            enable_learning_memory=os.getenv("ENABLE_LEARNING", "true").lower() == "true",
        )
    
    @classmethod
    def from_yaml(cls, path: str) -> "OrchestratorConfig":
        """Load configuration from YAML file."""
        import yaml
        with open(path, "r", encoding="utf-8") as f:
            config_dict = yaml.safe_load(f) or {}
        return cls(**config_dict)


# ==================== Prometheus Metrics ====================

class PrometheusMetrics:
    """Prometheus metrics collector for orchestrator."""
    
    def __init__(self, enabled: bool = False, port: int = 9090):
        self.enabled = enabled and PROMETHEUS_AVAILABLE
        
        if self.enabled:
            self.orchestrations_total = Counter(
                'orchestrator_runs_total',
                'Total number of orchestration runs',
                ['status']
            )
            
            self.stages_total = Counter(
                'orchestrator_stages_total',
                'Total number of stage executions',
                ['stage', 'status']
            )
            
            self.orchestration_duration = Histogram(
                'orchestrator_run_duration_seconds',
                'Duration of complete orchestration runs',
                buckets=[10, 30, 60, 120, 300, 600, 1800]
            )
            
            self.stage_duration = Histogram(
                'orchestrator_stage_duration_seconds',
                'Duration of individual stages',
                ['stage'],
                buckets=[1, 5, 10, 30, 60, 120]
            )
            
            self.active_orchestrations = Gauge(
                'orchestrator_active_runs',
                'Number of currently active orchestration runs'
            )
            
            # NEW: AI metrics
            self.rag_queries_total = Counter(
                'orchestrator_rag_queries_total',
                'Total RAG queries executed'
            )
            
            self.tests_selected = Gauge(
                'orchestrator_tests_selected',
                'Number of tests selected by intelligent selector'
            )
            
            try:
                start_http_server(port)
                logger.info("‚úÖ Prometheus metrics server started on port %d", port)
            except Exception as e:
                logger.warning("Failed to start Prometheus server: %s", e)
                self.enabled = False
    
    def record_orchestration_start(self):
        if self.enabled:
            self.active_orchestrations.inc()
    
    def record_orchestration_complete(self, success: bool, duration: float):
        if self.enabled:
            status = 'success' if success else 'failure'
            self.orchestrations_total.labels(status=status).inc()
            self.orchestration_duration.observe(duration)
            self.active_orchestrations.dec()
    
    def record_stage_complete(self, stage: str, success: bool, duration: float):
        if self.enabled:
            status = 'success' if success else 'failure'
            self.stages_total.labels(stage=stage, status=status).inc()
            self.stage_duration.labels(stage=stage).observe(duration)
    
    def record_rag_query(self):
        if self.enabled:
            self.rag_queries_total.inc()
    
    def record_tests_selected(self, count: int):
        if self.enabled:
            self.tests_selected.set(count)
    
    def export_latest(self) -> bytes:
        if self.enabled:
            return generate_latest()
        return b""


# ==================== Metrics & Observability ====================

@dataclass
class StageMetrics:
    stage_name: str
    start_time: float
    end_time: Optional[float] = None
    duration_s: Optional[float] = None
    success: bool = False
    error: Optional[str] = None
    retry_count: int = 0
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def complete(self, success: bool = True, error: Optional[str] = None):
        self.end_time = time.time()
        self.duration_s = round(self.end_time - self.start_time, 2)
        self.success = success
        self.error = error


@dataclass
class OrchestrationMetrics:
    run_id: str
    start_time: float
    end_time: Optional[float] = None
    total_duration_s: Optional[float] = None
    stages: List[StageMetrics] = field(default_factory=list)
    overall_success: bool = False
    requirement_text: Optional[str] = None
    target_url: Optional[str] = None
    
    # NEW: AI insights
    rag_recommendations: List[str] = field(default_factory=list)
    learning_insights: Dict[str, Any] = field(default_factory=dict)
    tests_selected: int = 0
    
    def add_stage(self, stage: StageMetrics):
        self.stages.append(stage)
        logger.info(
            "[%s] Stage '%s' completed: success=%s, duration=%.2fs, retries=%d",
            self.run_id, stage.stage_name, stage.success, stage.duration_s or 0, stage.retry_count,
        )
    
    def complete(self, success: bool = True):
        self.end_time = time.time()
        self.total_duration_s = round(self.end_time - self.start_time, 2)
        self.overall_success = success
        logger.info(
            "[%s] Orchestration completed: success=%s, duration=%.2fs, stages=%d",
            self.run_id, success, self.total_duration_s, len(self.stages),
        )
    
    def to_dict(self) -> Dict[str, Any]:
        return {**asdict(self), "stages": [asdict(s) for s in self.stages]}
    
    def export_jsonl(self, filepath: str):
        try:
            Path(filepath).parent.mkdir(parents=True, exist_ok=True)
            with open(filepath, "a", encoding="utf-8") as f:
                f.write(json.dumps(self.to_dict()) + "\n")
            logger.info("[%s] Exported metrics to %s", self.run_id, filepath)
        except Exception as e:
            logger.error("[%s] Failed to export metrics: %s", self.run_id, e)


# ==================== Event System ====================

class EventType(Enum):
    ORCHESTRATION_START = "orchestration_start"
    ORCHESTRATION_COMPLETE = "orchestration_complete"
    STAGE_START = "stage_start"
    STAGE_COMPLETE = "stage_complete"
    ERROR_OCCURRED = "error_occurred"
    VALIDATION_FAILED = "validation_failed"
    # NEW events
    RAG_QUERY = "rag_query"
    TESTS_SELECTED = "tests_selected"
    LEARNING_INSIGHT = "learning_insight"


@dataclass
class Event:
    event_type: EventType
    run_id: str
    timestamp: float
    data: Dict[str, Any] = field(default_factory=dict)


EventHandler = Callable[[Event], None]


class EventManager:
    def __init__(self):
        self._handlers: Dict[EventType, List[EventHandler]] = {event_type: [] for event_type in EventType}
    
    def subscribe(self, event_type: EventType, handler: EventHandler):
        self._handlers[event_type].append(handler)
    
    def unsubscribe(self, event_type: EventType, handler: EventHandler):
        if handler in self._handlers[event_type]:
            self._handlers[event_type].remove(handler)
    
    def fire(self, event: Event):
        handlers = self._handlers.get(event.event_type, [])
        for handler in handlers:
            try:
                handler(event)
            except Exception as e:
                logger.error("[%s] Event handler failed for %s: %s", event.run_id, event.event_type.value, e)


# ==================== Exceptions ====================

class OrchestrationError(Exception):
    pass


class StageFailureError(OrchestrationError):
    def __init__(self, stage_name: str, original_error: Exception):
        self.stage_name = stage_name
        self.original_error = original_error
        super().__init__(f"Stage '{stage_name}' failed: {original_error}")


class ValidationError(OrchestrationError):
    pass


class ResumeError(OrchestrationError):
    pass


# ==================== Dependency Injection Protocols ====================

class AgentProtocol(Protocol):
    def parse_requirement(self, text: str) -> Dict[str, Any]: ...


class ScraperProtocol(Protocol):
    def deep_scan(self, url: str) -> Dict[str, Any]: ...


class GeneratorProtocol(Protocol):
    def generate_plan(self, req: Dict[str, Any], scan: Dict[str, Any]) -> Dict[str, Any]: ...


class SecurityProtocol(Protocol):
    def plan_from_base_url(self, url: str) -> Optional[Dict[str, Any]]: ...


class RunnerProtocol(Protocol):
    def run_plan(self, plan: Dict[str, Any]) -> Dict[str, Any]: ...


# ==================== State Management ====================

@dataclass
class OrchestrationState:
    run_id: str
    stage: str
    timestamp: str
    requirement: Optional[Dict[str, Any]] = None
    scan_result: Optional[Dict[str, Any]] = None
    plan: Optional[Dict[str, Any]] = None
    execution_result: Optional[Dict[str, Any]] = None
    
    def save(self, path: str):
        state_dict = asdict(self)
        tmp_path = path + ".tmp"
        Path(tmp_path).parent.mkdir(parents=True, exist_ok=True)
        with open(tmp_path, "w", encoding="utf-8") as f:
            json.dump(state_dict, f, indent=2)
        Path(path).parent.mkdir(parents=True, exist_ok=True)
        Path(path).write_text(Path(tmp_path).read_text(encoding="utf-8"), encoding="utf-8")
        Path(tmp_path).unlink(missing_ok=True)
        logger.debug("[%s] Saved state to %s", self.run_id, path)
    
    @classmethod
    def load(cls, path: str) -> Optional["OrchestrationState"]:
        try:
            with open(path, "r", encoding="utf-8") as f:
                state_dict = json.load(f)
            logger.info("Loaded state from %s (run_id=%s)", path, state_dict.get("run_id"))
            return cls(**state_dict)
        except FileNotFoundError:
            logger.debug("No state file found at %s", path)
            return None
        except Exception as e:
            logger.warning("Failed to load state from %s: %s", path, e)
            return None


# ==================== Plan Validation ====================

PLAN_SCHEMA = {
    "$schema": "http://json-schema.org/draft-07/schema#",
    "type": "object",
    "required": ["suites"],
    "properties": {
        "project": {"type": "string"},
        "suites": {
            "type": "object",
            "minProperties": 1,
            "additionalProperties": {
                "type": "array",
                "items": {
                    "type": "object",
                    "required": ["name", "steps"],
                    "properties": {
                        "name": {"type": "string"},
                        "description": {"type": "string"},
                        "steps": {"type": "array", "items": {"type": "string"}},
                        "priority": {"type": "string"},
                        "tags": {"type": "array", "items": {"type": "string"}}
                    }
                }
            }
        },
        "ui_config": {
            "type": "object",
            "properties": {
                "browsers": {"type": "string"},
                "headless": {"type": "boolean"},
                "test_timeout_ms": {"type": "integer"},
                "expect_timeout_ms": {"type": "integer"},
                "workers": {"type": "integer"},
                "retries": {"type": "integer"}
            }
        }
    }
}


def validate_plan_schema(plan: Dict[str, Any], schema: Optional[Dict[str, Any]] = None, schema_file: Optional[str] = None) -> None:
    """Validate plan against JSON schema."""
    if not JSON_SCHEMA_AVAILABLE:
        logger.warning("JSON Schema validation skipped (jsonschema not installed)")
        return
    
    if schema_file and Path(schema_file).exists():
        try:
            schema = json.loads(Path(schema_file).read_text(encoding="utf-8"))
            logger.info("Using external plan schema: %s", schema_file)
        except Exception as e:
            logger.warning("Failed to read external schema (%s): %s; falling back to embedded", schema_file, e)
            schema = schema or PLAN_SCHEMA
    else:
        schema = schema or PLAN_SCHEMA
    
    try:
        jsonschema_validate(instance=plan, schema=schema)
        logger.debug("Plan schema validation passed")
    except JSONSchemaValidationError as e:
        raise ValidationError(f"Plan schema validation failed: {e.message}")


# ==================== Main Orchestrator ====================

class SpecOrchestrator:
    """Production-ready test specification orchestrator with AI enhancements."""
    
    def __init__(
        self,
        config: Optional[OrchestratorConfig] = None,
        agent: Optional[AgentProtocol] = None,
        scraper: Optional[ScraperProtocol] = None,
        generator: Optional[GeneratorProtocol] = None,
        security: Optional[SecurityProtocol] = None,
        runner: Optional[RunnerProtocol] = None,
        event_manager: Optional[EventManager] = None,
    ):
        self.config = config or OrchestratorConfig()
        
        # Core dependencies
        self.agent = agent or ConversationalAgent()
        self.scraper = scraper or self._create_default_scraper()
        self.generator = generator or TestGenerator(html_cache_dir=self.config.html_cache_dir)
        
        if SECURITY_ENGINE_AVAILABLE:
            self.security = security or SecurityEngine()
        else:
            self.security = None
            logger.warning("Security checks disabled (SecurityEngine not available)")
        
        self.runner = runner or Runner()
        
        # ‚ú® NEW: AI-Enhanced components
        self.rag = RAGEngine() if self.config.enable_rag else None
        self.learning_memory = LearningMemory() if self.config.enable_learning_memory else None
        self.test_selector = IntelligentTestSelector(
            learning_memory=self.learning_memory,
            rag_engine=self.rag
        ) if self.config.enable_intelligent_selection else None
        
        # Event system & Prometheus
        self.events = event_manager or EventManager()
        self.prometheus = PrometheusMetrics(
            enabled=self.config.enable_prometheus_metrics,
            port=self.config.prometheus_port
        )
        
        logger.info("SpecOrchestrator v2.0 initialized (AI-Enhanced)")
        if self.rag:
            logger.info("  ‚úÖ RAG Engine enabled")
        if self.learning_memory:
            logger.info("  ‚úÖ Learning Memory enabled")
        if self.test_selector:
            logger.info("  ‚úÖ Intelligent Test Selector enabled")
    
    def _create_default_scraper(self) -> WebScraper:
        """Factory method for creating default scraper with config."""
        return WebScraper(
            max_pages=self.config.scraper_max_pages,
            max_depth=self.config.scraper_max_depth,
            timeout_ms=self.config.scraper_timeout_ms,
            post_load_wait=self.config.scraper_post_load_wait_ms,
            same_origin=self.config.scraper_same_origin,
            capture_api=self.config.scraper_capture_api,
            rate_limit_delay=self.config.scraper_rate_limit_s,
            respect_robots=self.config.scraper_respect_robots,
            exclude_patterns=self.config.scraper_exclude or [],
            storage_state_path="auth/session_state.json",
        )
    
    # ==================== Event Hooks ====================
    
    def add_hook(self, event_type: EventType, handler: EventHandler):
        self.events.subscribe(event_type, handler)
        logger.info("Added hook for %s", event_type.value)
    
    def remove_hook(self, event_type: EventType, handler: EventHandler):
        self.events.unsubscribe(event_type, handler)
        logger.info("Removed hook for %s", event_type.value)
    
    # ==================== Validation ====================
    
    def _validate_requirement(self, req: Dict[str, Any]) -> None:
        if not req:
            raise ValidationError("Requirement parsing returned empty result")
        details = req.get("details", {}) or {}
        url = details.get("url")
        if not url:
            raise ValidationError("No URL found in requirement details")
        if not url.startswith(("http://", "https://")):
            raise ValidationError(f"Invalid URL format: {url}")
        logger.debug("Requirement validation passed: url=%s", url)
    
    def _validate_scan(self, scan: Dict[str, Any]) -> None:
        if not scan:
            raise ValidationError("Scan returned empty result")
        if scan.get("errors_count", 0) > 0 and scan.get("scanned_count", 0) == 0:
            raise ValidationError("Scan failed to retrieve any pages")
        logger.debug(
            "Scan validation passed: pages=%d, apis=%d",
            scan.get("scanned_count", 0),
            scan.get("api_calls_count", 0),
        )
    
    def _validate_plan(self, plan: Dict[str, Any]) -> None:
        if not plan:
            raise ValidationError("Plan generation returned empty result")
        if not plan.get("suites"):
            raise ValidationError("Plan has no test suites")
        if self.config.enable_plan_validation:
            validate_plan_schema(plan, schema=None, schema_file=self.config.plan_schema_file)
        logger.debug("Plan validation passed: suites=%d", len(plan.get("suites", {})))
    
    # ==================== Retry Logic ====================
    
    def _retry_with_backoff(self, func, stage_name: str, *args, **kwargs) -> Any:
        last_error = None
        for attempt in range(1, self.config.retry_max_attempts + 1):
            try:
                logger.info("Stage '%s': attempt %d/%d", stage_name, attempt, self.config.retry_max_attempts)
                result = func(*args, **kwargs)
                if attempt > 1:
                    logger.info("Stage '%s': succeeded on attempt %d", stage_name, attempt)
                return result
            except Exception as e:
                last_error = e
                logger.warning(
                    "Stage '%s': attempt %d/%d failed: %s",
                    stage_name, attempt, self.config.retry_max_attempts, e,
                )
                if attempt < self.config.retry_max_attempts:
                    delay = self.config.retry_delay_s * (2 ** (attempt - 1))
                    logger.info("Stage '%s': retrying in %.1fs...", stage_name, delay)
                    time.sleep(delay)
        raise StageFailureError(stage_name, last_error)
    
    # ==================== NEW: AI-Enhanced Methods ====================
    
    def _get_rag_recommendations(self, requirement_text: str) -> List[str]:
        """Get test recommendations from RAG engine"""
        if not self.rag:
            return []
        
        try:
            results = self.rag.search(requirement_text, top_k=self.config.rag_top_k)
            recommendations = [r['content'][:200] for r in results]
            
            self.events.fire(Event(
                EventType.RAG_QUERY,
                "system",
                time.time(),
                {"query": requirement_text, "results_count": len(results)}
            ))
            self.prometheus.record_rag_query()
            
            return recommendations
        except Exception as e:
            logger.error(f"RAG query failed: {e}")
            return []
    
    def _get_learning_insights(self, test_name: Optional[str] = None) -> Dict[str, Any]:
        """Get insights from learning memory"""
        if not self.learning_memory:
            return {}
        
        try:
            metrics = self.learning_memory.get_metrics()
            flaky_tests = self.learning_memory.get_flaky_tests()
            
            insights = {
                "total_executions": metrics.get("total_executions", 0),
                "pass_rate": metrics.get("pass_rate", 0.0),
                "heal_rate": metrics.get("heal_rate", 0.0),
                "flaky_test_count": len(flaky_tests),
                "flaky_tests": [t.test_name for t in flaky_tests[:5]]
            }
            
            self.events.fire(Event(
                EventType.LEARNING_INSIGHT,
                "system",
                time.time(),
                insights
            ))
            
            return insights
        except Exception as e:
            logger.error(f"Learning insights failed: {e}")
            return {}
    
    # ==================== Stage Methods (Enhanced) ====================
    
    def _parse_requirement_stage(
        self,
        requirement_text: str,
        metrics: OrchestrationMetrics,
        state: OrchestrationState
    ) -> Dict[str, Any]:
        stage = StageMetrics(stage_name="parse_requirement", start_time=time.time())
        self.events.fire(Event(EventType.STAGE_START, metrics.run_id, time.time(), {"stage": "parse_requirement"}))
        
        try:
            # Get RAG recommendations
            if self.rag:
                recommendations = self._get_rag_recommendations(requirement_text)
                metrics.rag_recommendations = recommendations
                logger.info(f"RAG recommendations: {len(recommendations)} found")
            
            req = self._retry_with_backoff(self.agent.parse_requirement, "parse_requirement", requirement_text)
            self._validate_requirement(req)
            
            state.requirement = req
            state.stage = "parsed"
            if self.config.enable_state_persistence:
                state.save(self.config.state_file)
            
            stage.complete(success=True)
            stage.metadata = {
                "has_url": bool(req.get("details", {}).get("url")),
                "rag_recommendations": len(metrics.rag_recommendations)
            }
            return req
        
        except Exception as e:
            stage.complete(success=False, error=str(e))
            self.events.fire(Event(EventType.ERROR_OCCURRED, metrics.run_id, time.time(), {
                "stage": "parse_requirement",
                "error": str(e)
            }))
            raise
        
        finally:
            metrics.add_stage(stage)
            self.prometheus.record_stage_complete(stage.stage_name, stage.success, stage.duration_s or 0)
            self.events.fire(Event(EventType.STAGE_COMPLETE, metrics.run_id, time.time(), {
                "stage": "parse_requirement",
                "success": stage.success
            }))
    
    def _scan_website_stage(
        self,
        target_url: str,
        metrics: OrchestrationMetrics,
        state: OrchestrationState
    ) -> Dict[str, Any]:
        stage = StageMetrics(stage_name="scan_website", start_time=time.time())
        self.events.fire(Event(EventType.STAGE_START, metrics.run_id, time.time(), {
            "stage": "scan_website",
            "url": target_url
        }))
        
        try:
            scan = self._retry_with_backoff(self.scraper.deep_scan, "scan_website", target_url)
            self._validate_scan(scan)
            
            state.scan_result = scan
            state.stage = "scanned"
            if self.config.enable_state_persistence:
                state.save(self.config.state_file)
            
            stage.complete(success=True)
            stage.metadata = {
                "pages_scraped": scan.get("scanned_count", 0),
                "api_calls_found": scan.get("api_calls_count", 0),
                "errors": scan.get("errors_count", 0),
            }
            return scan
        
        except Exception as e:
            stage.complete(success=False, error=str(e))
            self.events.fire(Event(EventType.ERROR_OCCURRED, metrics.run_id, time.time(), {
                "stage": "scan_website",
                "error": str(e)
            }))
            raise
        
        finally:
            metrics.add_stage(stage)
            self.prometheus.record_stage_complete(stage.stage_name, stage.success, stage.duration_s or 0)
            self.events.fire(Event(EventType.STAGE_COMPLETE, metrics.run_id, time.time(), {
                "stage": "scan_website",
                "success": stage.success
            }))
    
    def _generate_plan_stage(
        self,
        req: Dict[str, Any],
        scan: Dict[str, Any],
        metrics: OrchestrationMetrics,
        state: OrchestrationState
    ) -> Dict[str, Any]:
        stage = StageMetrics(stage_name="generate_plan", start_time=time.time())
        self.events.fire(Event(EventType.STAGE_START, metrics.run_id, time.time(), {"stage": "generate_plan"}))
        
        try:
            # Get learning insights
            if self.learning_memory:
                insights = self._get_learning_insights()
                metrics.learning_insights = insights
                logger.info(f"Learning insights: pass_rate={insights.get('pass_rate', 0):.1%}")
            
            plan = self._retry_with_backoff(self.generator.generate_plan, "generate_plan", req, scan)
            plan = self._augment_plan(plan, scan, req)
            self._validate_plan(plan)
            
            # ‚ú® NEW: Intelligent test selection
            if self.test_selector:
                # This would be used when we have a list of all available tests
                # For now, we just log that it's available
                logger.info("Intelligent test selector available for future optimization")
            
            state.plan = plan
            state.stage = "planned"
            if self.config.enable_state_persistence:
                state.save(self.config.state_file)
            
            stage.complete(success=True)
            stage.metadata = {
                "suites_count": len(plan.get("suites", {})),
                "has_api_suite": "api" in plan.get("suites", {}),
                "has_security_suite": "security" in plan.get("suites", {}),
                "has_performance_suite": "performance" in plan.get("suites", {}),
            }
            return plan
        
        except ValidationError as e:
            stage.complete(success=False, error=str(e))
            self.events.fire(Event(EventType.VALIDATION_FAILED, metrics.run_id, time.time(), {
                "stage": "generate_plan",
                "error": str(e)
            }))
            raise
        
        except Exception as e:
            stage.complete(success=False, error=str(e))
            self.events.fire(Event(EventType.ERROR_OCCURRED, metrics.run_id, time.time(), {
                "stage": "generate_plan",
                "error": str(e)
            }))
            raise
        
        finally:
            metrics.add_stage(stage)
            self.prometheus.record_stage_complete(stage.stage_name, stage.success, stage.duration_s or 0)
            self.events.fire(Event(EventType.STAGE_COMPLETE, metrics.run_id, time.time(), {
                "stage": "generate_plan",
                "success": stage.success
            }))
    
    def _execute_tests_stage(
        self,
        plan: Dict[str, Any],
        metrics: OrchestrationMetrics,
        state: OrchestrationState
    ) -> Dict[str, Any]:
        stage = StageMetrics(stage_name="execute_tests", start_time=time.time())
        self.events.fire(Event(EventType.STAGE_START, metrics.run_id, time.time(), {"stage": "execute_tests"}))
        
        if self.config.dry_run:
            logger.warning("[%s] DRY-RUN MODE: Skipping test execution", metrics.run_id)
            stage.complete(success=True)
            stage.metadata = {"dry_run": True}
            metrics.add_stage(stage)
            return {
                "dry_run": True,
                "message": "Execution skipped (dry-run mode)",
                "plan_valid": True
            }
        
        try:
            results = self._retry_with_backoff(self.runner.run_plan, "execute_tests", plan)
            
            state.execution_result = results
            state.stage = "executed"
            if self.config.enable_state_persistence:
                state.save(self.config.state_file)
            
            # Extract metrics
            passed = results.get("total", {}).get("PASS") if isinstance(results.get("total"), dict) else results.get("passed", 0)
            failed = results.get("total", {}).get("FAIL") if isinstance(results.get("total"), dict) else results.get("failed", 0)
            total_tests = (passed or 0) + (failed or 0)
            
            metrics.tests_selected = total_tests
            self.prometheus.record_tests_selected(total_tests)
            
            stage.complete(success=True)
            stage.metadata = {
                "total_tests": total_tests,
                "passed": passed or 0,
                "failed": failed or 0
            }
            return results
        
        except Exception as e:
            stage.complete(success=False, error=str(e))
            self.events.fire(Event(EventType.ERROR_OCCURRED, metrics.run_id, time.time(), {
                "stage": "execute_tests",
                "error": str(e)
            }))
            raise
        
        finally:
            metrics.add_stage(stage)
            self.prometheus.record_stage_complete(stage.stage_name, stage.success, stage.duration_s or 0)
            self.events.fire(Event(EventType.STAGE_COMPLETE, metrics.run_id, time.time(), {
                "stage": "execute_tests",
                "success": stage.success
            }))
    
    # ==================== Plan Augmentation (Preserved) ====================
    
    def _augment_plan(self, plan: Dict[str, Any], scan: Dict[str, Any], requirement: Dict[str, Any]) -> Dict[str, Any]:
        """Augment plan with API discovery, security checks, and UI config."""
        plan.setdefault("plan_meta", {})
        plan.setdefault("suites", {})
        plan.setdefault("artifacts", {})
        
        base_url = (requirement.get("details", {}) or {}).get("url") or plan.get("project") or ""
        
        # 1) API Discovery Suite
        if self.config.enable_api_discovery:
            api_calls: List[Dict[str, Any]] = scan.get("api_calls", []) or []
            api_suite = self._build_api_suite(api_calls, base_url)
            if api_suite:
                plan["suites"].setdefault("api", [])
                plan["suites"]["api"].append(api_suite)
                logger.info("Added API discovery suite with %d step(s)", len(api_suite.get("steps", [])))
        
        # 2) Security Suite
        if self.config.enable_security_checks and self.security:
            try:
                sec_suite = self.security.plan_from_base_url(base_url)
                if sec_suite:
                    plan["suites"].setdefault("security", [])
                    plan["suites"]["security"].append(sec_suite)
                    logger.info("Added security suite")
            except Exception as e:
                logger.warning("Failed to generate security suite (non-fatal): %s", e)
        
        # 3) UI Configuration
        plan["ui_config"] = {
            "browsers": self.config.ui_browsers,
            "headless": self.config.ui_headless,
            "test_timeout_ms": self.config.ui_test_timeout_ms,
            "expect_timeout_ms": self.config.ui_expect_timeout_ms,
            "workers": self.config.ui_workers,
            "retries": self.config.ui_retries,
            "fully_parallel": self.config.ui_fully_parallel,
            "forbid_only": self.config.ui_forbid_only,
            "enable_junit": self.config.ui_enable_junit,
        }
        
        # 4) Metadata
        plan["artifacts"].setdefault("ui_workspace", None)
        plan["plan_meta"]["orchestrated_at"] = datetime.utcnow().isoformat() + "Z"
        plan["plan_meta"]["scan_stats"] = {
            "pages": scan.get("scanned_count", 0),
            "api_calls": scan.get("api_calls_count", 0),
            "errors": scan.get("errors_count", 0),
        }
        
        return plan
    
    def _build_api_suite(self, api_calls: List[Dict[str, Any]], base_url: str) -> Optional[Dict[str, Any]]:
        if not api_calls:
            return None
        
        seen = set()
        steps = []
        
        for call in api_calls[: self.config.api_discovery_limit]:
            method = (call.get("method") or "GET").upper()
            url = call.get("url")
            if not url:
                continue
            
            key = f"{method}:{url}"
            if key in seen:
                continue
            seen.add(key)
            
            status = call.get("status")
            ctype = (call.get("content_type") or "").lower()
            
            if status is not None:
                if 200 <= int(status) < 300:
                    step = f"{method} {url} expect {status}"
                elif 300 <= int(status) < 400:
                    step = f"{method} {url} expect 3xx"
                else:
                    step = f"{method} {url} expect {status}"
            else:
                if "json" in ctype:
                    step = f"{method} {url} expect 2xx application/json"
                else:
                    step = f"{method} {url} expect 2xx"
            
            steps.append(step)
        
        if not steps:
            return None
        
        return {
            "name": "Discovered API health checks",
            "description": f"Auto-discovered {len(steps)} API endpoints",
            "steps": steps,
            "priority": "P1",
            "tags": ["discovery", "health", "api"],
        }
    
    # ==================== Main Entry Point ====================
    
    def run(self, requirement_text: str, run_id: Optional[str] = None) -> Dict[str, Any]:
        """Execute complete orchestration workflow."""
        run_id = run_id or f"orch_{uuid.uuid4().hex[:8]}"
        metrics = OrchestrationMetrics(
            run_id=run_id,
            start_time=time.time(),
            requirement_text=requirement_text
        )
        state = OrchestrationState(
            run_id=run_id,
            stage="init",
            timestamp=datetime.utcnow().isoformat() + "Z"
        )
        
        logger.info("=" * 60)
        logger.info("[%s] Starting orchestration v2.0 (AI-Enhanced)", run_id)
        if self.config.dry_run:
            logger.warning("[%s] DRY-RUN MODE ENABLED", run_id)
        logger.info("=" * 60)
        
        self.events.fire(Event(
            EventType.ORCHESTRATION_START,
            run_id,
            time.time(),
            {"requirement_text": requirement_text}
        ))
        self.prometheus.record_orchestration_start()
        
        try:
            req = self._parse_requirement_stage(requirement_text, metrics, state)
            target_url = (req.get("details", {}) or {}).get("url")
            metrics.target_url = target_url
            
            scan = self._scan_website_stage(target_url, metrics, state)
            plan = self._generate_plan_stage(req, scan, metrics, state)
            results = self._execute_tests_stage(plan, metrics, state)
            
            metrics.complete(success=True)
            logger.info("=" * 60)
            logger.info("[%s] Orchestration completed successfully", run_id)
            logger.info("=" * 60)
            
            self.events.fire(Event(
                EventType.ORCHESTRATION_COMPLETE,
                run_id,
                time.time(),
                {"success": True}
            ))
            self.prometheus.record_orchestration_complete(True, metrics.total_duration_s or 0)
            
            if self.config.enable_jsonl_export:
                metrics_file = Path(self.config.metrics_export_dir) / f"metrics_{run_id}.jsonl"
                metrics.export_jsonl(str(metrics_file))
            
            return {
                "run_id": run_id,
                "success": True,
                "results": results,
                "metrics": metrics.to_dict(),
                "plan": plan,
                # NEW: AI insights
                "rag_recommendations": metrics.rag_recommendations,
                "learning_insights": metrics.learning_insights,
            }
        
        except Exception as e:
            metrics.complete(success=False)
            logger.error("=" * 60)
            logger.error("[%s] Orchestration failed: %s", run_id, e, exc_info=True)
            logger.error("=" * 60)
            
            self.events.fire(Event(
                EventType.ORCHESTRATION_COMPLETE,
                run_id,
                time.time(),
                {"success": False, "error": str(e)}
            ))
            self.prometheus.record_orchestration_complete(False, metrics.total_duration_s or 0)
            
            if self.config.enable_jsonl_export:
                metrics_file = Path(self.config.metrics_export_dir) / f"metrics_{run_id}.jsonl"
                metrics.export_jsonl(str(metrics_file))
            
            return {
                "run_id": run_id,
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__,
                "metrics": metrics.to_dict(),
                "partial_state": asdict(state),
            }
    
    # ==================== State Recovery (Preserved) ====================
    
    def resume(self, state_file: Optional[str] = None) -> Dict[str, Any]:
        """Resume orchestration from saved state."""
        state_file = state_file or self.config.state_file
        state = OrchestrationState.load(state_file)
        if not state:
            raise ResumeError(f"No state file found at {state_file}")
        
        logger.info("[%s] Resuming orchestration from stage: %s", state.run_id, state.stage)
        metrics = OrchestrationMetrics(run_id=state.run_id, start_time=time.time())
        
        try:
            if state.stage in ("init", "parsed"):
                if not state.requirement:
                    raise ResumeError("Cannot resume: no requirement in state")
                req = state.requirement
                target_url = (req.get("details", {}) or {}).get("url")
                scan = self._scan_website_stage(target_url, metrics, state)
                plan = self._generate_plan_stage(req, scan, metrics, state)
                results = self._execute_tests_stage(plan, metrics, state)
            
            elif state.stage == "scanned":
                if not state.requirement or not state.scan_result:
                    raise ResumeError("Cannot resume: missing requirement or scan result")
                plan = self._generate_plan_stage(state.requirement, state.scan_result, metrics, state)
                results = self._execute_tests_stage(plan, metrics, state)
            
            elif state.stage == "planned":
                if not state.plan:
                    raise ResumeError("Cannot resume: no plan in state")
                results = self._execute_tests_stage(state.plan, metrics, state)
            
            elif state.stage == "executed":
                logger.info("[%s] Orchestration already completed", state.run_id)
                return {
                    "run_id": state.run_id,
                    "success": True,
                    "resumed": True,
                    "results": state.execution_result,
                    "message": "Orchestration was already complete"
                }
            
            else:
                raise ResumeError(f"Unknown stage: {state.stage}")
            
            metrics.complete(success=True)
            logger.info("[%s] Resume completed successfully", state.run_id)
            return {
                "run_id": state.run_id,
                "success": True,
                "resumed": True,
                "results": results,
                "metrics": metrics.to_dict()
            }
        
        except Exception as e:
            metrics.complete(success=False)
            logger.error("[%s] Resume failed: %s", state.run_id, e, exc_info=True)
            return {
                "run_id": state.run_id,
                "success": False,
                "resumed": True,
                "error": str(e),
                "error_type": type(e).__name__,
                "metrics": metrics.to_dict()
            }


# ==================== Example Usage ====================

if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    
    def log_stage_completion(event: Event):
        print(f"üìä [Hook] Stage completed: {event.data.get('stage')}, success={event.data.get('success')}")
    
    def alert_on_error(event: Event):
        print(f"üö® [Hook] Error in {event.data.get('stage')}: {event.data.get('error')}")
    
    def log_rag_query(event: Event):
        print(f"üîç [Hook] RAG query: {event.data.get('results_count')} recommendations found")
    
    config = OrchestratorConfig(
        scraper_max_pages=20,
        dry_run=False,
        enable_prometheus_metrics=False,
        enable_jsonl_export=True,
        enable_rag=True,
        enable_learning_memory=True,
    )
    
    orchestrator = SpecOrchestrator(config=config)
    orchestrator.add_hook(EventType.STAGE_COMPLETE, log_stage_completion)
    orchestrator.add_hook(EventType.ERROR_OCCURRED, alert_on_error)
    orchestrator.add_hook(EventType.RAG_QUERY, log_rag_query)
    
    requirement = "Test the login functionality of https://example.com"
    result = orchestrator.run(requirement)
    
    print("\n" + "=" * 60)
    print("ORCHESTRATION RESULT")
    print("=" * 60)
    print(f"Run ID: {result['run_id']}")
    print(f"Success: {result['success']}")
    print(f"Duration: {result.get('metrics', {}).get('total_duration_s')}s")
    
    if result.get('rag_recommendations'):
        print(f"\nüîç RAG Recommendations: {len(result['rag_recommendations'])}")
        for i, rec in enumerate(result['rag_recommendations'][:3], 1):
            print(f"  {i}. {rec[:100]}...")
    
    if result.get('learning_insights'):
        insights = result['learning_insights']
        print(f"\nüìä Learning Insights:")
        print(f"  Total Executions: {insights.get('total_executions', 0)}")
        print(f"  Pass Rate: {insights.get('pass_rate', 0):.1%}")
        print(f"  Flaky Tests: {insights.get('flaky_test_count', 0)}")
    
    print("=" * 60 + "\n")
